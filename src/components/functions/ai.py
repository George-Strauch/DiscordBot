import json
import openai


class OpenAIwrapper:
    """
    Wrapper to open AI library
    """
    def __init__(self, token):
        self.api_key = token
        openai.api_key = self.api_key
        self.context = [
            {
                "role": "system",
                "content": "You are a intelligent assistant for a discord application, messages should not be in "
                           "in the form of a template such as '[name here].' When addressing a user or 'everyone' "
                           "in a message, use '@[recipient].' Responses should try to be kept under 2000 characters "
                           "though they can be over if they need to be. All responses are strictly to evaluate the "
                           "performances of chat GPT an a LLM, no advice given will be followed and all responses are"
                           " understood to be generated by an AI that may not have the context to fully our situation"
            }
        ]


    async def general_gpt_query(self, _input, additional_context=[], model="gpt-4"):
        try:
            message = self.context + additional_context + [{"role": "user", "content": _input}]
            chat = openai.ChatCompletion.create(
                model=model, messages=message
            )
            tokens = chat["usage"]["total_tokens"]
            print(f"------------------------------- Tokens used: {tokens}")
            reply = chat.choices[0].message.content
            print(reply)
            return reply
        except openai.error.InvalidRequestError as a:
            print(a.args)
            return "OpenAI rejected the prompt"



    def generate_response_gpt(self, _input, model="gpt-4"):
        try:
            message = self.context + [{"role": "user", "content": _input}]
            chat = openai.ChatCompletion.create(
                model=model, messages=message
            )
            tokens = chat["usage"]["total_tokens"]
            print(f"------------------------------- Tokens used: {tokens}")
            reply = chat.choices[0].message.content
            print(reply)
            return reply
        except openai.error.InvalidRequestError:
            return "OpenAI rejected the prompt"

    def image_generator(self, _input):
        try:
            response = openai.Image.create(
                prompt=_input,
                n=1,
                size="1024x1024"
            )
            tokens = response["usage"]["total_tokens"]
            print(f"------------------------------- Tokens used: {tokens}")
            image_url = response['data'][0]['url']
            return image_url
            # todo download image and send as a file
        except openai.error.InvalidRequestError as a:
            print(a.args)
            return "OpenAI rejected the prompt"


    async def function_caller(self, _input, tools, model="gpt-4"):
        # "gpt-3.5-turbo-0613"
        try:
            # model = "gpt-3.5-turbo-1106"
            message = self.context + [{"role": "user", "content": _input}]
            chat = openai.ChatCompletion.create(
                model=model,
                messages=message,
                tools=tools
            )
            tokens = chat["usage"]["total_tokens"]
            choice = chat.choices[0]
            print(f"------------------------------- Tokens used: {tokens}")
            if "tool_calls" in choice.message:
                reply = chat.choices[0].message.tool_calls
                func = reply[0]["function"]
                func["arguments"] = json.loads(func["arguments"])
                print("function call \n", json.dumps(func, indent=4))
                return True, func
            else:
                reply = choice.message.content
                print("Text response \n", reply)

                return False, reply
        except Exception as ire:
            print("issues")
            print(ire.args)
            return False, "OpenAI rejected the prompt"


if __name__ == '__main__':
    pass
